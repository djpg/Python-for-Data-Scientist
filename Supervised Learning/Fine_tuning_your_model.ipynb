{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import randint\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score, mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression, ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas para clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ya hemos visto en los problemas de clasificación la métrica que se usa por defecto a la hora de ver lo bien que se comporta un determinado modelo es la precisión (accuracy). Sin embargo existen determinadas situaciones en las que hacer uso de esta medida no es una buena idea. Supongamos el caso en el cual estamos haciendo uso de un clasificador de spam donde tenemos que el 99% de nuestro emails son útiles y tan solo el 1% es spam. En este caso, si cada vez que llegase un correo el modelo dijese que es el correo no es spam tendría una precisión del 99% pero en absoluto haría lo que queremos, que es detectar los correos que son spam. Para este tipo de casos podemos hacer uso de la matriz de confusión y a partir de esta obtener las medidas de : accuracy, precision, recall y support. La precision se define como el cociente entre tp/(tp+fp), supongamos que estamos intentando identificar perros y  gatos en una imagen. En esta imagen tenemos un total de 12 perros y el resto son gatos. Supongamos que nuestro algoritmo clasifica como perros a 8 elementos, de estos 8 elementos 5 son verdaderamente perros los otros 3 son gatos entonces nuestra precision = 5/(5+3) = 5/8. Por otro lado el recall se define como tp/(tp+fn), en nuestro ejemplo nuestra recall sería 5/(5+7) = 5/12. En el siguiente problema vamos a tratar con el conjunto de datos diabetes.csv, que vamos a tratar de clasificar a gente como diabética o no diabética en función de una serie de características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[176  30]\n",
      " [ 56  46]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.85      0.80       206\n",
      "          1       0.61      0.45      0.52       102\n",
      "\n",
      "avg / total       0.71      0.72      0.71       308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Cargamos los datos \n",
    "df = pd.read_csv('diabetes.csv')\n",
    "x = df.drop('diabetes', axis = 1)\n",
    "y = df['diabetes']\n",
    "#Dibimos entre train y test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.4, random_state = 42)\n",
    "#Cremos nuestro clasificador knn con k = 6\n",
    "knn = KNeighborsClassifier(n_neighbors = 6)\n",
    "#Fijamos el predictor\n",
    "knn.fit(x_train, y_train)\n",
    "#Predecimos\n",
    "y_pred = knn.predict(x_test)\n",
    "#Generamos la matriz de confusión y sus métricas\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La métrica support nos indica el número de muestras que hemos clasificado bien como personas con diabetes y no diabetes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métrica Logloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La métrica logloss cuantifica la precisión de un clasificador al penalizar las clasificaciones falsas. Supongamos la situación donde estamos intentando predecir si un email es spam o no. El 99% de nuestros emails no serán spam y el 1% serán spam, ya sabemos que hacer uso de accuracy como métrica no es adecuado, logloss lo que hace es penalizar fuertemente aquellas situaciones en las que el email se clasifico como spam si este no lo era y viceversa. Es decir, en los casos que el clasificador asigna una probabilidad muy pequeña a la clase correcta, su contribución a la medida logloss será muy grande. Para calcular esta métrica podemos hacer uso de la siguiente función"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_loss(predicted, actual, eps = 1e-14):\n",
    "    '''Calcula la métrica logloss entre el valor predicho y el actual cuando estos son\n",
    "    un array 1D'''\n",
    "    predicted = np.clip(predicted, eps, 1 - eps)\n",
    "    loss = -1 * np.mean(actual * np.log(predicted) + (1 - actual) * np.log(1 - predicted))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Logística y Curva ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La regresión logística pese a su nombre se trata de un algoritmo usado para problemas de clasificación. Se trata de un método que puede ser usado en los problemas de clasificació binaria. Sobre todon en aquellos casos en los que ponemos un umbra de probabilidad entre un tipo u otro. Por ejemplo para un probabilidad superior a 0.7 consideramos 0 y para una probabilidad inferior consideramos 1. A continuación haremos uso de la regresión logística para el caso de diabetes y veremos si consigue mejores resultados que nuestro algoritmo knn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[174  32]\n",
      " [ 36  66]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.84      0.84       206\n",
      "          1       0.67      0.65      0.66       102\n",
      "\n",
      "avg / total       0.78      0.78      0.78       308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Separamos en train y test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.4, random_state=42)\n",
    "#Nos creamos nuestro regresor logístico\n",
    "reg_log = LogisticRegression()\n",
    "#Fijamos el regresor\n",
    "reg_log.fit(x_train, y_train)\n",
    "#Predecimos\n",
    "y_pred = reg_log.predict(x_test)\n",
    "#Visualizamos nuestra matriz de confusión y sus métricas\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification_reports y la matriz de confusión son una buena forma de evaluar cuantitativamente el rendimiento de un modelo, mientras que la curva ROC nos proporciona una forma más visual de evaluar un modelo. El método predict.proba(), nos devuelve la probabilidad de que un determinado ejemplo pertenezca a una clase, este método está incorporado en muchos clasificadores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSgoiIpJLSUFERHL9f6BufAHI+JhYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb180e5ae80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Computamos la probabilidad de que nuestras predicciones pertenezcan a una determinada clase\n",
    "y_pred_prob = reg_log.predict_proba(x_test)[:, 1]\n",
    "#Generamos los valores de la curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "#Mostramos la curva ROC\n",
    "_ = plt.plot([0,1], [0, 1], 'k--')\n",
    "_ = plt.plot(fpr, tpr, label = 'Logistic Regression')\n",
    "_ = plt.xlabel('False Positive Rate')\n",
    "_ = plt.ylabel('True Positive Rate')\n",
    "_ = plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El área bajo esta curva, se trata de una de las métricas más populares a la hora de evaluar un modelo de clasificación. Un  modelo con un área bajo la curva ROC de 1 indicaría un modelo perfecto, cuanto más elevada sea este área mejor sera capaz nuestro modelo de clasificar de formar correcta nuestro problema binario. A continuación vamos a calcular el área bajo la curva ROC para nuestro conjunto de datos diabetes.csv, realizando un 5-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8269084332762231\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = reg_log.predict_proba(x_test)[:, 1]\n",
    "#Obtenemos el área bajo la curva roc\n",
    "print('AUC: {}'.format(roc_auc_score(y_test, y_pred_prob)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC [ 0.7987037   0.80777778  0.81962963  0.86584906  0.85037736]\n"
     ]
    }
   ],
   "source": [
    "#Ahora obtenemos el área bajo la curva ROC pero haciendo uso de 5-fold\n",
    "cv_auc = cross_val_score(reg_log, x, y, cv = 5, scoring = 'roc_auc')\n",
    "print('AUC {}'.format(cv_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la hora de elegir los parámetros que mejor resultado nos proporciona un modelo, python nos proporiciona la opción de realizar un tuning de parámetros. Para comprender esto mejor, vamos a realizar un ejemplo para el caso del dataset diabetes.csv, donde vamos a tratar de encontrar el mejor parámetro C, que nos controla que el modelo no este overfitting o underfitting. En este caso no vamos a dividir los datos en train y test, ya que únicamente nos queremos centrar en el tuning de parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameters: {'C': 268.26957952797272}\n",
      "Best score is 0.7708333333333334\n"
     ]
    }
   ],
   "source": [
    "#Nos creamos nuestro grid de parámetros para nuestro parámetro C\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c_space}\n",
    "\n",
    "# Instantiate a logistic regression classifier: logreg\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv=5)\n",
    "\n",
    "# Fit it to the data\n",
    "logreg_cv.fit(x, y)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_)) \n",
    "print(\"Best score is {}\".format(logreg_cv.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizar un GridSearchCV puede ser computacionalmente bastante costoso, especialmente si estamos buscando un gran espacio de hiperparámetro y manejando múltiples hiperparámetros. Una solución a esto es el uso de RandomizedSearchCV, que no prueba todos los valores posibles para el hiperparámetro. En su lugar, se fijan un número fijo de hiperparámetros a partir de distribuciones de probabilidad configuradas. Para ver su potencial, vamos a hacer uso de un nuevo modelo los árboles de decisión. Para un árbol de decisión el número de parámetros que necesitamos optimos que necesitamos encontrar es bastante elevado: max_features, max_depth, min_samples_leaf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los parámetros óptimos son: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 8, 'min_samples_leaf': 1}\n",
      "El mejor resultado es: 0.7395833333333334\n"
     ]
    }
   ],
   "source": [
    "#Nos creamos nuestra distribución de parámetros\n",
    "param_dist = {'max_depth': [3,None],\n",
    "             'max_features': randint(1,9),\n",
    "             'min_samples_leaf': randint(1,9),\n",
    "             'criterion': ['gini', 'entropy']}\n",
    "#Inicializamos nuestro decision tree\n",
    "tree = DecisionTreeClassifier()\n",
    "#Hacemos nuestro tuning de parámetros\n",
    "tree_cv = RandomizedSearchCV(tree, param_dist, cv = 5)\n",
    "#Hacemos el fit\n",
    "tree_cv.fit(x,y)\n",
    "#Mostramos los resultados\n",
    "print('Los parámetros óptimos son: {}'.format(tree_cv.best_params_))\n",
    "print('El mejor resultado es: {}'.format(tree_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debemos tener claro que RandomizedSearchCV nunca superará a GridSearchCV, pero en numerosas ocasiones es utilizado ya que computacionalmente es menos costoso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta ahora hemos hecho uso de del tuning de parámetros sin realizar conjunto de train&test, esto no es lo ideal. Lo ideal es finalmente tener un conjunto de datos que nuestro algoritmo no haya visto, para ver si nuestro algoritmo está generalizando de forma adecuada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La regresión logística además del hiperparámetro C dispone del hiperparámetro penalty que nos indica si debemos de hacer uso de la regularización L1 O L2. A continuación vamos a proceder a realizar un tuning de parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los mejores parámetros son: {'penalty': 'l2', 'C': 31.622776601683793}\n",
      "El mejor resultado en términos de accuracy es: 0.7673913043478261\n"
     ]
    }
   ],
   "source": [
    "#Nos creamos nuestro grid de parámetros\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c_space, 'penalty': ['l1', 'l2']}\n",
    "#Hacemos nuestra partición en train y test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.4, random_state = 42)\n",
    "#Nos creamos nuestro regresor logístico\n",
    "logreg = LogisticRegression()\n",
    "#Nos creamos nuestro 5-flod\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv = 5)\n",
    "#Hacemos un fit\n",
    "logreg_cv.fit(x_train, y_train)\n",
    "#Mostramos los resultados por pantalla\n",
    "print('Los mejores parámetros son: {}'.format(logreg_cv.best_params_))\n",
    "print('El mejor resultado en términos de accuracy es: {}'.format(logreg_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ya vimos a la hora de regularizar la regresión de Lasso hacía uso de la penalización L1 mientras que la regresión de Ridge hace uso de la penalización L2. Existe otro tipo de regularización de regresión conocido con red elástica. En la regularización de red elástica, la penalización que se realiza es una combinación lineal de las dos anteriores: a*L1 + b*L2. \n",
    "En scikit-learn, este término es conocido como el parámetro l1_ratio. Un l1_ratio de 1 corresponde a una penalización de L1 mientras que cualquier otro valor corresponde a una combinación lineal entre L1 y L2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros óptimos para el regresor elástico: {'l1_ratio': 0.0}\n",
      "Elastic Net R2: 0.24765337510702687\n",
      "Elastic Net mse: 0.16664179543611013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#Dividimos nuestro conjunto de entrenamiento en train y test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.4, random_state = 42)\n",
    "#Nos creamos nuestr grid de parámetros\n",
    "l1_space = np.linspace(0, 1, 100)\n",
    "param_grid = {'l1_ratio': l1_space}\n",
    "#Fijamos nuestro regresor elástico\n",
    "elastic_reg = ElasticNet()\n",
    "#Computamos nuestro grid\n",
    "gm_cv = GridSearchCV(elastic_reg, param_grid, cv = 5)\n",
    "#Hacemos el fit\n",
    "gm_cv.fit(x_train, y_train)\n",
    "#Hacemos predicciones\n",
    "y_pred = gm_cv.predict(x_test)\n",
    "#Calculamos la métrica R^2 y también el erro cuadrático medio\n",
    "r2 = gm_cv.score(x_test, y_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "#Mostramos los resultados por pantalla\n",
    "print('Parámetros óptimos para el regresor elástico: {}'.format(gm_cv.best_params_))\n",
    "print('Elastic Net R2: {}'.format(r2))\n",
    "print('Elastic Net mse: {}'.format(mse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
